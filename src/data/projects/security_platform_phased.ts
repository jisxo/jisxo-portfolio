import { Project } from './types';

export const securityPlatformPhasedProject: Project = {
  title: '그룹사 통합 보안 데이터 플랫폼 구축',
  duration: '2021.06 - 2022.09',
  role: '데이터 엔지니어',
  description:
    '수작업 중심 보안 관제를 자동화하고 대용량 처리 병목을 해소한 뒤 이기종 로그를 단일 스키마로 통합한 단계형 데이터 플랫폼 구축 프로젝트입니다.',
  overview: {
    background: [
      '수작업 관제로 인해 탐지 지연과 운영 부담이 지속되었습니다.',
      '장비별 로그 형식이 달라 통합 분석이 어려웠습니다.',
      '비정형 대용량 데이터 처리 중 메모리 병목이 반복되었습니다.',
    ],
    objective: [
      '1단계에서 수집·전처리·탐지 파이프라인을 자동화했습니다.',
      '2단계에서 JSON 분할 처리로 대용량 처리 병목을 완화했습니다.',
      '3단계에서 이기종 로그를 단일 표준 스키마로 통합했습니다.',
    ],
    outcome: [
      '수집과 분석 파이프라인 자동화율 100%를 달성했습니다.',
      '대용량 처리 구간의 메모리 병목을 해소했습니다.',
      '통합 적재 데이터 정합성 100%를 확보했습니다.',
    ],
  },
  image: '/images/thumbnails/security_platform_phased.png',
  domain: '보안 데이터 플랫폼',
  tags: [
    'Python',
    'Apache Airflow',
    'ETL',
    'NLP',
    'JSON Chunking',
    'Data Standardization',
    'Docker',
  ],
  star: {
    situation: `수작업 관제 환경에서는 처리 지연이 누적됐고 이기종 로그 구조 차이로 통합 분석 품질이 일정하지 않았습니다. 대용량 비정형 데이터 처리 구간에서는 메모리 병목으로 재시도가 반복됐습니다.`,
    action: `단계별로 자동화 파이프라인을 구축하고 JSON 분할 처리 전략을 도입해 처리 안정성을 확보했습니다. 이후 로그 표준 스키마를 설계해 소스별 데이터를 동일 구조로 적재했습니다.`,
    result: `관제 운영을 자동화해 반복 업무를 줄였고 대용량 처리 실패를 안정화했습니다. 통합 적재 데이터 정합성 100% 기준을 유지할 수 있는 구조를 마련했습니다.`,
  },
  contributions: [
    '수집·전처리·탐지 자동화 파이프라인 설계 및 구축',
    'JSON 분할 처리 적용으로 대용량 처리 병목 완화',
    '이기종 로그 통합 표준 스키마 설계',
    '적재 데이터 정합성 검증 기준 수립',
  ],
};
